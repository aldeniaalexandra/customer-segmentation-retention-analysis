{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9490a445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0830e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (541909, 8)\n",
      "\n",
      "Column Names and Data Types:\n",
      "InvoiceNo       object\n",
      "StockCode       object\n",
      "Description     object\n",
      "Quantity         int64\n",
      "InvoiceDate     object\n",
      "UnitPrice      float64\n",
      "CustomerID     float64\n",
      "Country         object\n",
      "dtype: object\n",
      "\n",
      "First 5 rows:\n",
      "  InvoiceNo StockCode                          Description  Quantity  \\\n",
      "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
      "1    536365     71053                  WHITE METAL LANTERN         6   \n",
      "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
      "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
      "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
      "\n",
      "      InvoiceDate  UnitPrice  CustomerID         Country  \n",
      "0  12/1/2010 8:26       2.55     17850.0  United Kingdom  \n",
      "1  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n",
      "2  12/1/2010 8:26       2.75     17850.0  United Kingdom  \n",
      "3  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n",
      "4  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 541909 entries, 0 to 541908\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   InvoiceNo    541909 non-null  object \n",
      " 1   StockCode    541909 non-null  object \n",
      " 2   Description  540455 non-null  object \n",
      " 3   Quantity     541909 non-null  int64  \n",
      " 4   InvoiceDate  541909 non-null  object \n",
      " 5   UnitPrice    541909 non-null  float64\n",
      " 6   CustomerID   406829 non-null  float64\n",
      " 7   Country      541909 non-null  object \n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 33.1+ MB\n",
      "\n",
      "Missing Values:\n",
      "InvoiceNo           0\n",
      "StockCode           0\n",
      "Description      1454\n",
      "Quantity            0\n",
      "InvoiceDate         0\n",
      "UnitPrice           0\n",
      "CustomerID     135080\n",
      "Country             0\n",
      "dtype: int64\n",
      "\n",
      "Unique Customers: 4372\n",
      "Unique Products: 4070\n",
      "Unique Countries: 38\n",
      "Date Range: 1/10/2011 10:04 to 9/9/2011 9:52\n",
      "\n",
      "Numerical Statistics:\n",
      "            Quantity      UnitPrice     CustomerID\n",
      "count  541909.000000  541909.000000  406829.000000\n",
      "mean        9.552250       4.611114   15287.690570\n",
      "std       218.081158      96.759853    1713.600303\n",
      "min    -80995.000000  -11062.060000   12346.000000\n",
      "25%         1.000000       1.250000   13953.000000\n",
      "50%         3.000000       2.080000   15152.000000\n",
      "75%        10.000000       4.130000   16791.000000\n",
      "max     80995.000000   38970.000000   18287.000000\n",
      "\n",
      "Negative Quantities (Returns): 10624\n",
      "Zero Unit Price: 2517\n"
     ]
    }
   ],
   "source": [
    "# Load the customer dataset\n",
    "df = pd.read_csv('data/online_retail.csv', encoding='latin1')\n",
    "\n",
    "# Basic dataset information\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nColumn Names and Data Types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nDataset Info:\")\n",
    "df.info()\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Unique values analysis for customer segmentation\n",
    "print(f\"\\nUnique Customers: {df['CustomerID'].nunique()}\")\n",
    "print(f\"Unique Products: {df['StockCode'].nunique()}\")\n",
    "print(f\"Unique Countries: {df['Country'].nunique()}\")\n",
    "print(f\"Date Range: {df['InvoiceDate'].min()} to {df['InvoiceDate'].max()}\")\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nNumerical Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Check for negative quantities (returns)\n",
    "print(f\"\\nNegative Quantities (Returns): {len(df[df['Quantity'] < 0])}\")\n",
    "print(f\"Zero Unit Price: {len(df[df['UnitPrice'] <= 0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25433932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records with CustomerID: 406829\n",
      "Total Revenue: $8,300,065.81\n",
      "\n",
      "Sample Customer Transaction Patterns:\n",
      "                InvoiceDate                        Quantity  UnitPrice\n",
      "                        min              max count      sum       mean\n",
      "CustomerID                                                            \n",
      "12346.0     1/18/2011 10:01  1/18/2011 10:17     2        0   1.040000\n",
      "12347.0     1/26/2011 14:30    8/2/2011 8:48   182     2458   2.644011\n",
      "12348.0     1/25/2011 10:42  9/25/2011 13:13    31     2341   5.764839\n",
      "12349.0     11/21/2011 9:51  11/21/2011 9:51    73      631   8.289041\n",
      "12350.0      2/2/2011 16:01   2/2/2011 16:01    17      197   3.841176\n",
      "12352.0     11/3/2011 14:37  9/28/2011 14:58    95      470  23.274737\n",
      "12353.0     5/19/2011 17:47  5/19/2011 17:47     4       20   6.075000\n",
      "12354.0     4/21/2011 13:11  4/21/2011 13:11    58      530   4.503793\n",
      "12355.0      5/9/2011 13:49   5/9/2011 13:49    13      240   4.203846\n",
      "12356.0      1/18/2011 9:50   4/8/2011 12:33    59     1591   3.201186\n"
     ]
    }
   ],
   "source": [
    "# Customer behavior overview (for non-null CustomerID)\n",
    "customer_data = df[df['CustomerID'].notna()].copy()\n",
    "\n",
    "print(f\"Records with CustomerID: {len(customer_data)}\")\n",
    "print(f\"Total Revenue: ${(customer_data['Quantity'] * customer_data['UnitPrice']).sum():,.2f}\")\n",
    "\n",
    "# Preview customer transaction patterns\n",
    "customer_preview = customer_data.groupby('CustomerID').agg({\n",
    "    'InvoiceDate': ['min', 'max', 'count'],\n",
    "    'Quantity': 'sum',\n",
    "    'UnitPrice': 'mean'\n",
    "}).head(10)\n",
    "\n",
    "print(\"\\nSample Customer Transaction Patterns:\")\n",
    "print(customer_preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48b86a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Cleaning Summary:\n",
      "Original records with CustomerID: 406,829\n",
      "After removing returns and zero prices: 324,716\n",
      "Records removed: 82,113\n",
      "Final dataset shape: (324716, 9)\n",
      "\n",
      "Date range: 2010-12-01 08:26:00 to 2011-12-09 12:50:00\n",
      "Unique customers: 4,146\n",
      "Total revenue: $3,524,535.90\n",
      "Average order value: $10.85\n"
     ]
    }
   ],
   "source": [
    "# Start with customer data (non-null CustomerID only)\n",
    "df_clean = customer_data.copy()\n",
    "\n",
    "# Convert InvoiceDate to datetime\n",
    "df_clean['InvoiceDate'] = pd.to_datetime(df_clean['InvoiceDate'])\n",
    "\n",
    "# Remove returns (negative quantities) and zero prices for positive sales analysis\n",
    "df_clean = df_clean[(df_clean['Quantity'] > 0) & (df_clean['UnitPrice'] > 0)].copy()\n",
    "\n",
    "# Calculate total amount per transaction\n",
    "df_clean['TotalAmount'] = df_clean['Quantity'] * df_clean['UnitPrice']\n",
    "\n",
    "# Remove outliers using IQR method for Quantity and UnitPrice\n",
    "def remove_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "\n",
    "# Apply outlier removal\n",
    "df_clean = remove_outliers(df_clean, 'Quantity')\n",
    "df_clean = remove_outliers(df_clean, 'UnitPrice')\n",
    "df_clean = remove_outliers(df_clean, 'TotalAmount')\n",
    "\n",
    "print(\"Data Cleaning Summary:\")\n",
    "print(f\"Original records with CustomerID: {len(customer_data):,}\")\n",
    "print(f\"After removing returns and zero prices: {len(df_clean):,}\")\n",
    "print(f\"Records removed: {len(customer_data) - len(df_clean):,}\")\n",
    "print(f\"Final dataset shape: {df_clean.shape}\")\n",
    "\n",
    "# Verify data quality\n",
    "print(f\"\\nDate range: {df_clean['InvoiceDate'].min()} to {df_clean['InvoiceDate'].max()}\")\n",
    "print(f\"Unique customers: {df_clean['CustomerID'].nunique():,}\")\n",
    "print(f\"Total revenue: ${df_clean['TotalAmount'].sum():,.2f}\")\n",
    "print(f\"Average order value: ${df_clean['TotalAmount'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79a20e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis Date: 2011-12-10 12:50:00\n",
      "\n",
      "RFM Dataset Shape: (4146, 12)\n",
      "\n",
      "RFM Statistics:\n",
      "           Recency    Frequency      Monetary\n",
      "count  4146.000000  4146.000000   4146.000000\n",
      "mean     93.181380     3.918234    850.105138\n",
      "std     100.015984     6.813902   1767.635549\n",
      "min       1.000000     1.000000      1.700000\n",
      "25%      18.000000     1.000000    173.970000\n",
      "50%      51.000000     2.000000    405.625000\n",
      "75%     145.000000     4.000000    964.527500\n",
      "max     374.000000   193.000000  70409.910000\n",
      "\n",
      "Cleaned datasets saved!\n"
     ]
    }
   ],
   "source": [
    "# Set analysis date (day after the last transaction date)\n",
    "analysis_date = df_clean['InvoiceDate'].max() + timedelta(days=1)\n",
    "print(f\"Analysis Date: {analysis_date}\")\n",
    "\n",
    "# Calculate RFM metrics\n",
    "rfm_data = df_clean.groupby('CustomerID').agg({\n",
    "    'InvoiceDate': lambda x: (analysis_date - x.max()).days,  # Recency\n",
    "    'InvoiceNo': 'nunique',  # Frequency\n",
    "    'TotalAmount': 'sum'     # Monetary\n",
    "}).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "rfm_data.columns = ['CustomerID', 'Recency', 'Frequency', 'Monetary']\n",
    "\n",
    "# Add additional customer metrics\n",
    "customer_metrics = df_clean.groupby('CustomerID').agg({\n",
    "    'InvoiceDate': ['min', 'max'],\n",
    "    'Quantity': 'sum',\n",
    "    'StockCode': 'nunique',\n",
    "    'Country': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "customer_metrics.columns = ['CustomerID', 'FirstPurchase', 'LastPurchase', \n",
    "                           'TotalQuantity', 'UniqueProducts', 'Country']\n",
    "\n",
    "# Merge RFM with additional metrics\n",
    "rfm_complete = rfm_data.merge(customer_metrics, on='CustomerID')\n",
    "\n",
    "# Calculate customer lifetime (days)\n",
    "rfm_complete['CustomerLifetime'] = (rfm_complete['LastPurchase'] - \n",
    "                                   rfm_complete['FirstPurchase']).dt.days + 1\n",
    "\n",
    "# Calculate average order value and purchase frequency\n",
    "rfm_complete['AvgOrderValue'] = rfm_complete['Monetary'] / rfm_complete['Frequency']\n",
    "rfm_complete['AvgDaysBetweenPurchases'] = rfm_complete['CustomerLifetime'] / rfm_complete['Frequency']\n",
    "\n",
    "print(f\"\\nRFM Dataset Shape: {rfm_complete.shape}\")\n",
    "print(f\"\\nRFM Statistics:\")\n",
    "print(rfm_complete[['Recency', 'Frequency', 'Monetary']].describe())\n",
    "\n",
    "# Save cleaned data\n",
    "df_clean.to_csv('data/online_retail_cleaned.csv', index=False)\n",
    "rfm_complete.to_csv('data/rfm_customer_data.csv', index=False)\n",
    "print(\"\\nCleaned datasets saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47a92124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFM Scoring Complete!\n",
      "RFM Score Distribution:\n",
      "count    4146.000000\n",
      "mean        8.999518\n",
      "std         3.579664\n",
      "min         3.000000\n",
      "25%         6.000000\n",
      "50%         9.000000\n",
      "75%        12.000000\n",
      "max        15.000000\n",
      "Name: RFM_Value, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create RFM scores using quintiles (1-5 scale)\n",
    "rfm_scores = rfm_complete.copy()\n",
    "\n",
    "# Calculate quintile scores (5 = best, 1 = worst)\n",
    "rfm_scores['R_Score'] = pd.qcut(rfm_scores['Recency'].rank(method='first'), 5, labels=[5,4,3,2,1])\n",
    "rfm_scores['F_Score'] = pd.qcut(rfm_scores['Frequency'].rank(method='first'), 5, labels=[1,2,3,4,5])\n",
    "rfm_scores['M_Score'] = pd.qcut(rfm_scores['Monetary'].rank(method='first'), 5, labels=[1,2,3,4,5])\n",
    "\n",
    "# Convert scores to integers\n",
    "rfm_scores['R_Score'] = rfm_scores['R_Score'].astype(int)\n",
    "rfm_scores['F_Score'] = rfm_scores['F_Score'].astype(int) \n",
    "rfm_scores['M_Score'] = rfm_scores['M_Score'].astype(int)\n",
    "\n",
    "# Create combined RFM score\n",
    "rfm_scores['RFM_Score'] = rfm_scores['R_Score'].astype(str) + \\\n",
    "                         rfm_scores['F_Score'].astype(str) + \\\n",
    "                         rfm_scores['M_Score'].astype(str)\n",
    "\n",
    "# Calculate overall customer value score\n",
    "rfm_scores['RFM_Value'] = rfm_scores['R_Score'] + rfm_scores['F_Score'] + rfm_scores['M_Score']\n",
    "\n",
    "print(\"RFM Scoring Complete!\")\n",
    "print(f\"RFM Score Distribution:\")\n",
    "print(rfm_scores['RFM_Value'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30d1e48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Segmentation Analysis:\n",
      "                     Customer_Count  Avg_Recency  Avg_Frequency  Avg_Monetary  \\\n",
      "Customer_Segment                                                                \n",
      "Champions                       895        14.76          10.37       2410.91   \n",
      "At Risk                         437        75.13           4.47       1075.21   \n",
      "Loyal Customers                 501        17.12           3.11        582.22   \n",
      "Cannot Lose Them                433       147.88           2.42        517.01   \n",
      "Potential Loyalists             611        35.86           1.56        285.10   \n",
      "New Customers                   650       146.15           1.06        211.82   \n",
      "Lost Customers                  498       253.82           1.01        106.79   \n",
      "Promising                       121       201.39           2.13        134.55   \n",
      "\n",
      "                     Avg_RFM_Score  Percentage  Total_Revenue  \\\n",
      "Customer_Segment                                                \n",
      "Champions                    14.03       21.59     2157764.48   \n",
      "At Risk                      10.82       10.54      469866.21   \n",
      "Loyal Customers              11.13       12.08      291694.32   \n",
      "Cannot Lose Them              7.92       10.44      223867.30   \n",
      "Potential Loyalists           8.07       14.74      174193.29   \n",
      "New Customers                 5.49       15.68      137686.18   \n",
      "Lost Customers                3.67       12.01       53183.04   \n",
      "Promising                     5.74        2.92       16281.08   \n",
      "\n",
      "                     Revenue_Percentage  \n",
      "Customer_Segment                         \n",
      "Champions                         61.22  \n",
      "At Risk                           13.33  \n",
      "Loyal Customers                    8.28  \n",
      "Cannot Lose Them                   6.35  \n",
      "Potential Loyalists                4.94  \n",
      "New Customers                      3.91  \n",
      "Lost Customers                     1.51  \n",
      "Promising                          0.46  \n",
      "\n",
      "Top 3 Segments by Revenue:\n",
      "Champions: 61.22% of revenue from 21.59% of customers\n",
      "At Risk: 13.33% of revenue from 10.54% of customers\n",
      "Loyal Customers: 8.28% of revenue from 12.08% of customers\n"
     ]
    }
   ],
   "source": [
    "# Define customer segments based on RFM scores\n",
    "def segment_customers(row):\n",
    "    if row['RFM_Value'] >= 13:\n",
    "        return 'Champions'\n",
    "    elif row['RFM_Value'] >= 10:\n",
    "        if row['R_Score'] >= 4:\n",
    "            return 'Loyal Customers'\n",
    "        else:\n",
    "            return 'At Risk'\n",
    "    elif row['RFM_Value'] >= 7:\n",
    "        if row['R_Score'] >= 3:\n",
    "            return 'Potential Loyalists'\n",
    "        else:\n",
    "            return 'Cannot Lose Them'\n",
    "    elif row['RFM_Value'] >= 5:\n",
    "        if row['F_Score'] <= 2:\n",
    "            return 'New Customers'\n",
    "        else:\n",
    "            return 'Promising'\n",
    "    else:\n",
    "        if row['R_Score'] >= 3:\n",
    "            return 'Need Attention'\n",
    "        else:\n",
    "            return 'Lost Customers'\n",
    "\n",
    "# Apply segmentation\n",
    "rfm_scores['Customer_Segment'] = rfm_scores.apply(segment_customers, axis=1)\n",
    "\n",
    "# Analyze segments\n",
    "segment_analysis = rfm_scores.groupby('Customer_Segment').agg({\n",
    "    'CustomerID': 'count',\n",
    "    'Recency': 'mean',\n",
    "    'Frequency': 'mean', \n",
    "    'Monetary': 'mean',\n",
    "    'RFM_Value': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "segment_analysis.columns = ['Customer_Count', 'Avg_Recency', 'Avg_Frequency', \n",
    "                           'Avg_Monetary', 'Avg_RFM_Score']\n",
    "\n",
    "# Calculate segment percentages and revenue contribution\n",
    "segment_analysis['Percentage'] = (segment_analysis['Customer_Count'] / len(rfm_scores) * 100).round(2)\n",
    "segment_analysis['Total_Revenue'] = rfm_scores.groupby('Customer_Segment')['Monetary'].sum().round(2)\n",
    "segment_analysis['Revenue_Percentage'] = (segment_analysis['Total_Revenue'] / rfm_scores['Monetary'].sum() * 100).round(2)\n",
    "\n",
    "print(\"Customer Segmentation Analysis:\")\n",
    "print(segment_analysis.sort_values('Total_Revenue', ascending=False))\n",
    "\n",
    "# Top customer segments by value\n",
    "print(f\"\\nTop 3 Segments by Revenue:\")\n",
    "top_segments = segment_analysis.sort_values('Total_Revenue', ascending=False).head(3)\n",
    "for segment in top_segments.index:\n",
    "    revenue_pct = top_segments.loc[segment, 'Revenue_Percentage']\n",
    "    customer_pct = top_segments.loc[segment, 'Percentage']\n",
    "    print(f\"{segment}: {revenue_pct}% of revenue from {customer_pct}% of customers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fcc796b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Machine Learning Cluster Analysis:\n",
      "            CustomerID  Recency  Frequency  Monetary  AvgOrderValue  \\\n",
      "ML_Cluster                                                            \n",
      "0                  449    64.15       2.98   1526.03         563.91   \n",
      "1                 2424    44.34       3.45    574.53         172.00   \n",
      "2                  990   248.43       1.48    224.88         158.09   \n",
      "3                    3     1.33     168.00  40040.93         240.35   \n",
      "4                  280    14.62      16.31   3942.59         279.14   \n",
      "\n",
      "            UniqueProducts  \n",
      "ML_Cluster                  \n",
      "0                    93.77  \n",
      "1                    41.14  \n",
      "2                    19.22  \n",
      "3                  1436.33  \n",
      "4                   216.01  \n",
      "\n",
      "Segmentation analysis saved!\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for clustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Select features for clustering\n",
    "clustering_features = ['Recency', 'Frequency', 'Monetary', 'AvgOrderValue', 'UniqueProducts']\n",
    "X = rfm_scores[clustering_features].copy()\n",
    "\n",
    "# Handle any potential missing values\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Find optimal number of clusters using elbow method\n",
    "inertias = []\n",
    "K_range = range(2, 11)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_scaled)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "\n",
    "# Apply K-Means with optimal clusters (let's use 5)\n",
    "kmeans_final = KMeans(n_clusters=5, random_state=42, n_init=10)\n",
    "rfm_scores['ML_Cluster'] = kmeans_final.fit_predict(X_scaled)\n",
    "\n",
    "# Analyze ML clusters\n",
    "cluster_analysis = rfm_scores.groupby('ML_Cluster').agg({\n",
    "    'CustomerID': 'count',\n",
    "    'Recency': 'mean',\n",
    "    'Frequency': 'mean',\n",
    "    'Monetary': 'mean',\n",
    "    'AvgOrderValue': 'mean',\n",
    "    'UniqueProducts': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "print(f\"\\nMachine Learning Cluster Analysis:\")\n",
    "print(cluster_analysis)\n",
    "\n",
    "# Save segmented data\n",
    "rfm_scores.to_csv('output/rfm_customer_segments.csv', index=False)\n",
    "segment_analysis.to_csv('output/customer_segment_analysis.csv')\n",
    "print(f\"\\nSegmentation analysis saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "198fd4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Churn Rate: 33.53%\n",
      "\n",
      "Churn Analysis by Customer Segment:\n",
      "                     Total_Customers  Churned_Customers  Churn_Rate  \\\n",
      "Customer_Segment                                                      \n",
      "Lost Customers                   498                480       0.964   \n",
      "Promising                        121                112       0.926   \n",
      "Cannot Lose Them                 433                329       0.760   \n",
      "New Customers                    650                365       0.562   \n",
      "At Risk                          437                104       0.238   \n",
      "Champions                        895                  0       0.000   \n",
      "Loyal Customers                  501                  0       0.000   \n",
      "Potential Loyalists              611                  0       0.000   \n",
      "\n",
      "                     Revenue_At_Risk  \n",
      "Customer_Segment                      \n",
      "Lost Customers          51268.450560  \n",
      "Promising               15076.280080  \n",
      "Cannot Lose Them       170139.149520  \n",
      "New Customers           77379.633722  \n",
      "At Risk                111828.157980  \n",
      "Champions                   0.000000  \n",
      "Loyal Customers             0.000000  \n",
      "Potential Loyalists         0.000000  \n"
     ]
    }
   ],
   "source": [
    "# Define churn based on recency (customers who haven't purchased in 90+ days)\n",
    "rfm_churn = rfm_scores.copy()\n",
    "\n",
    "# Create churn label (1 = churned, 0 = active)\n",
    "churn_threshold = 90  # days\n",
    "rfm_churn['Churned'] = (rfm_churn['Recency'] > churn_threshold).astype(int)\n",
    "\n",
    "# Create additional features for churn prediction\n",
    "rfm_churn['DaysActive'] = rfm_churn['CustomerLifetime']\n",
    "rfm_churn['PurchaseFrequency'] = rfm_churn['Frequency'] / (rfm_churn['CustomerLifetime'] / 30)  # purchases per month\n",
    "rfm_churn['MonthsSinceFirstPurchase'] = rfm_churn['CustomerLifetime'] / 30\n",
    "rfm_churn['IsOneTimeBuyer'] = (rfm_churn['Frequency'] == 1).astype(int)\n",
    "\n",
    "# Calculate churn rate\n",
    "churn_rate = rfm_churn['Churned'].mean()\n",
    "print(f\"Overall Churn Rate: {churn_rate:.2%}\")\n",
    "\n",
    "# Churn by segment analysis\n",
    "churn_by_segment = rfm_churn.groupby('Customer_Segment').agg({\n",
    "    'Churned': ['count', 'sum', 'mean'],\n",
    "    'Monetary': 'sum'\n",
    "}).round(3)\n",
    "churn_by_segment.columns = ['Total_Customers', 'Churned_Customers', 'Churn_Rate', 'Revenue_At_Risk']\n",
    "churn_by_segment['Revenue_At_Risk'] = churn_by_segment['Revenue_At_Risk'] * churn_by_segment['Churn_Rate']\n",
    "\n",
    "print(f\"\\nChurn Analysis by Customer Segment:\")\n",
    "print(churn_by_segment.sort_values('Churn_Rate', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ba5b6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Churn Prediction Model Performance:\n",
      "ROC AUC Score: 1.000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       552\n",
      "           1       1.00      1.00      1.00       278\n",
      "\n",
      "    accuracy                           1.00       830\n",
      "   macro avg       1.00      1.00      1.00       830\n",
      "weighted avg       1.00      1.00      1.00       830\n",
      "\n",
      "\n",
      "Top 5 Features for Churn Prediction:\n",
      "                    Feature  Importance\n",
      "0                   Recency    0.728410\n",
      "9                 RFM_Value    0.151187\n",
      "5          CustomerLifetime    0.036547\n",
      "7  MonthsSinceFirstPurchase    0.029297\n",
      "2                  Monetary    0.014761\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Prepare features for ML model\n",
    "feature_columns = ['Recency', 'Frequency', 'Monetary', 'AvgOrderValue', \n",
    "                  'UniqueProducts', 'CustomerLifetime', 'PurchaseFrequency', \n",
    "                  'MonthsSinceFirstPurchase', 'IsOneTimeBuyer', 'RFM_Value']\n",
    "\n",
    "X = rfm_churn[feature_columns].copy()\n",
    "y = rfm_churn['Churned'].copy()\n",
    "\n",
    "# Handle missing values\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Train Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "y_pred_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Model evaluation\n",
    "print(f\"\\nChurn Prediction Model Performance:\")\n",
    "print(f\"ROC AUC Score: {roc_auc_score(y_test, y_pred_proba):.3f}\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': feature_columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 5 Features for Churn Prediction:\")\n",
    "print(feature_importance.head())\n",
    "\n",
    "# Add churn probability to dataset\n",
    "rfm_churn['Churn_Probability'] = rf_model.predict_proba(X)[:, 1]\n",
    "rfm_churn['Churn_Risk_Level'] = pd.cut(rfm_churn['Churn_Probability'], \n",
    "                                      bins=[0, 0.3, 0.7, 1.0], \n",
    "                                      labels=['Low', 'Medium', 'High'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbdd2742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Customer Lifetime Value Analysis:\n",
      "                      Avg_CLV  Median_CLV    Total_CLV  Customer_Count  \\\n",
      "Customer_Segment                                                         \n",
      "New Customers        25538.30    21737.45  16599895.52             650   \n",
      "Potential Loyalists  20787.86    12963.58  12701380.24             611   \n",
      "Lost Customers       13671.89    11836.17   6808600.79             498   \n",
      "Cannot Lose Them     12939.20      569.01   5602675.65             433   \n",
      "Loyal Customers       3272.75      442.13   1639645.55             501   \n",
      "Champions             1642.61      892.71   1470140.31             895   \n",
      "At Risk               2905.08      633.89   1269521.88             437   \n",
      "Promising             2531.91      262.77    306361.45             121   \n",
      "\n",
      "                     Avg_Churn_Risk  \n",
      "Customer_Segment                     \n",
      "New Customers                  0.56  \n",
      "Potential Loyalists            0.00  \n",
      "Lost Customers                 0.96  \n",
      "Cannot Lose Them               0.75  \n",
      "Loyal Customers                0.00  \n",
      "Champions                      0.00  \n",
      "At Risk                        0.23  \n",
      "Promising                      0.92  \n",
      "\n",
      "High-Value At-Risk Customers (Top 10):\n",
      "      CustomerID  Customer_Segment            CLV  Churn_Probability  Monetary\n",
      "26       12378.0  Cannot Lose Them  409672.297906           0.972000   3188.62\n",
      "3847     17850.0           At Risk  272918.719904           0.980000   4248.44\n",
      "272      12688.0  Cannot Lose Them  253721.313266           0.982000   1974.80\n",
      "120      12501.0  Cannot Lose Them  239827.540318           0.998000   1866.66\n",
      "1055     13850.0  Cannot Lose Them  190018.608413           0.972000   1478.98\n",
      "1239     14105.0     New Customers  111190.012224           1.000000    865.43\n",
      "3061     16714.0  Cannot Lose Them  107778.881544           0.992727    838.88\n",
      "147      12534.0  Cannot Lose Them  106474.814636           0.992727    828.73\n",
      "1912     15069.0  Cannot Lose Them  106057.256266           0.992727    825.48\n",
      "2450     15832.0  Cannot Lose Them  105544.623068           0.992727    821.49\n",
      "\n",
      "Comprehensive customer analysis saved to output folder!\n"
     ]
    }
   ],
   "source": [
    "# Calculate Customer Lifetime Value (CLV)\n",
    "# CLV = Average Order Value × Purchase Frequency × Customer Lifespan\n",
    "\n",
    "# Average customer lifespan in months (using historical data)\n",
    "avg_customer_lifespan_months = rfm_churn['MonthsSinceFirstPurchase'].mean()\n",
    "\n",
    "# Calculate CLV for each customer\n",
    "rfm_churn['Monthly_Purchase_Rate'] = rfm_churn['Frequency'] / rfm_churn['MonthsSinceFirstPurchase']\n",
    "rfm_churn['Monthly_Revenue'] = rfm_churn['AvgOrderValue'] * rfm_churn['Monthly_Purchase_Rate']\n",
    "rfm_churn['CLV'] = rfm_churn['Monthly_Revenue'] * avg_customer_lifespan_months\n",
    "\n",
    "# CLV by segment\n",
    "clv_analysis = rfm_churn.groupby('Customer_Segment').agg({\n",
    "    'CLV': ['mean', 'median', 'sum'],\n",
    "    'CustomerID': 'count',\n",
    "    'Churn_Probability': 'mean'\n",
    "}).round(2)\n",
    "clv_analysis.columns = ['Avg_CLV', 'Median_CLV', 'Total_CLV', 'Customer_Count', 'Avg_Churn_Risk']\n",
    "\n",
    "print(f\"\\nCustomer Lifetime Value Analysis:\")\n",
    "print(clv_analysis.sort_values('Total_CLV', ascending=False))\n",
    "\n",
    "# High-value at-risk customers\n",
    "high_risk_valuable = rfm_churn[\n",
    "    (rfm_churn['CLV'] > rfm_churn['CLV'].quantile(0.8)) & \n",
    "    (rfm_churn['Churn_Risk_Level'] == 'High')\n",
    "][['CustomerID', 'Customer_Segment', 'CLV', 'Churn_Probability', 'Monetary']].sort_values('CLV', ascending=False)\n",
    "\n",
    "print(f\"\\nHigh-Value At-Risk Customers (Top 10):\")\n",
    "print(high_risk_valuable.head(10))\n",
    "\n",
    "# Save comprehensive analysis\n",
    "rfm_churn.to_csv('output/comprehensive_customer_analysis.csv', index=False)\n",
    "churn_by_segment.to_csv('output/churn_analysis_by_segment.csv')\n",
    "clv_analysis.to_csv('output/customer_lifetime_value_analysis.csv')\n",
    "feature_importance.to_csv('output/churn_prediction_feature_importance.csv', index=False)\n",
    "high_risk_valuable.to_csv('output/high_value_at_risk_customers.csv', index=False)\n",
    "\n",
    "print(f\"\\nComprehensive customer analysis saved to output folder!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e56b74c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power BI datasets created:\n",
      "Main customer dataset: (4146, 20)\n",
      "Segment KPIs: (8, 13)\n",
      "Monthly cohorts: (12100, 8)\n",
      "Country analysis: (37, 6)\n"
     ]
    }
   ],
   "source": [
    "# 1. Main customer dashboard dataset\n",
    "powerbi_main = rfm_churn[['CustomerID', 'Country', 'Customer_Segment', 'ML_Cluster',\n",
    "                         'Recency', 'Frequency', 'Monetary', 'RFM_Value',\n",
    "                         'AvgOrderValue', 'UniqueProducts', 'CustomerLifetime',\n",
    "                         'CLV', 'Churn_Probability', 'Churn_Risk_Level', 'Churned',\n",
    "                         'FirstPurchase', 'LastPurchase']].copy()\n",
    "\n",
    "# Add categorical variables for better Power BI visualization\n",
    "powerbi_main['RFM_Category'] = pd.cut(powerbi_main['RFM_Value'], \n",
    "                                     bins=[0, 5, 8, 11, 15], \n",
    "                                     labels=['Low Value', 'Medium Value', 'High Value', 'Premium'])\n",
    "\n",
    "powerbi_main['CLV_Category'] = pd.qcut(powerbi_main['CLV'], \n",
    "                                      q=4, \n",
    "                                      labels=['Low CLV', 'Medium CLV', 'High CLV', 'Premium CLV'])\n",
    "\n",
    "powerbi_main['Recency_Category'] = pd.cut(powerbi_main['Recency'], \n",
    "                                         bins=[0, 30, 90, 180, 400], \n",
    "                                         labels=['Active', 'Recent', 'Dormant', 'Lost'])\n",
    "\n",
    "# 2. Segment performance summary for KPI cards\n",
    "segment_kpis = rfm_churn.groupby('Customer_Segment').agg({\n",
    "    'CustomerID': 'count',\n",
    "    'Monetary': ['sum', 'mean'],\n",
    "    'Frequency': 'mean',\n",
    "    'Recency': 'mean',\n",
    "    'CLV': ['sum', 'mean'],\n",
    "    'Churn_Probability': 'mean',\n",
    "    'AvgOrderValue': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "segment_kpis.columns = ['Customer_Count', 'Total_Revenue', 'Avg_Revenue_Per_Customer',\n",
    "                       'Avg_Frequency', 'Avg_Recency', 'Total_CLV', 'Avg_CLV', \n",
    "                       'Avg_Churn_Risk', 'Avg_Order_Value']\n",
    "\n",
    "segment_kpis = segment_kpis.reset_index()\n",
    "\n",
    "# Add percentage calculations\n",
    "segment_kpis['Customer_Percentage'] = (segment_kpis['Customer_Count'] / segment_kpis['Customer_Count'].sum() * 100).round(2)\n",
    "segment_kpis['Revenue_Percentage'] = (segment_kpis['Total_Revenue'] / segment_kpis['Total_Revenue'].sum() * 100).round(2)\n",
    "segment_kpis['CLV_Percentage'] = (segment_kpis['Total_CLV'] / segment_kpis['Total_CLV'].sum() * 100).round(2)\n",
    "\n",
    "# 3. Time-based analysis (monthly cohorts)\n",
    "df_clean_time = df_clean.copy()\n",
    "df_clean_time['YearMonth'] = df_clean_time['InvoiceDate'].dt.to_period('M')\n",
    "\n",
    "monthly_cohorts = df_clean_time.groupby(['CustomerID', 'YearMonth']).agg({\n",
    "    'TotalAmount': 'sum',\n",
    "    'InvoiceNo': 'nunique',\n",
    "    'Quantity': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "monthly_cohorts.columns = ['CustomerID', 'YearMonth', 'Monthly_Revenue', 'Monthly_Orders', 'Monthly_Quantity']\n",
    "monthly_cohorts['YearMonth'] = monthly_cohorts['YearMonth'].astype(str)\n",
    "\n",
    "# Merge with customer segments\n",
    "monthly_cohorts = monthly_cohorts.merge(\n",
    "    powerbi_main[['CustomerID', 'Customer_Segment', 'CLV_Category', 'Country']], \n",
    "    on='CustomerID'\n",
    ")\n",
    "\n",
    "# 4. Country performance analysis\n",
    "country_analysis = rfm_churn.groupby('Country').agg({\n",
    "    'CustomerID': 'count',\n",
    "    'Monetary': 'sum',\n",
    "    'CLV': 'sum',\n",
    "    'Churn_Probability': 'mean',\n",
    "    'RFM_Value': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "country_analysis.columns = ['Total_Customers', 'Total_Revenue', 'Total_CLV', 'Avg_Churn_Risk', 'Avg_RFM_Score']\n",
    "country_analysis = country_analysis.reset_index()\n",
    "\n",
    "print(\"Power BI datasets created:\")\n",
    "print(f\"Main customer dataset: {powerbi_main.shape}\")\n",
    "print(f\"Segment KPIs: {segment_kpis.shape}\")\n",
    "print(f\"Monthly cohorts: {monthly_cohorts.shape}\")\n",
    "print(f\"Country analysis: {country_analysis.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e99b9339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All Power BI datasets exported successfully:\n",
      "- powerbi_customer_analysis.csv (4,146 customers)\n",
      "- powerbi_segment_kpis.csv (8 segments)\n",
      "- powerbi_monthly_cohorts.csv (monthly analysis)\n",
      "- powerbi_country_analysis.csv (geographic analysis)\n",
      "- powerbi_champions_customers.csv (top customers)\n",
      "- powerbi_at_risk_high_value.csv (retention focus)\n",
      "- powerbi_data_dictionary.txt\n",
      "\n",
      "Ready for Power BI dashboard creation!\n",
      "\n",
      "Key Insights for Dashboard:\n",
      "• Champions segment: 61.22% of revenue\n",
      "• At-risk revenue: $457,758\n",
      "• Average CLV: $11,191\n",
      "• Customers needing attention: 203 high-value at-risk customers\n"
     ]
    }
   ],
   "source": [
    "# Export to CSV files for Power BI\n",
    "powerbi_main.to_csv('output/powerbi_customer_analysis.csv', index=False)\n",
    "segment_kpis.to_csv('output/powerbi_segment_kpis.csv', index=False)\n",
    "monthly_cohorts.to_csv('output/powerbi_monthly_cohorts.csv', index=False)\n",
    "country_analysis.to_csv('output/powerbi_country_analysis.csv', index=False)\n",
    "\n",
    "# Create high-priority customer lists for targeted analysis\n",
    "champions_list = rfm_churn[rfm_churn['Customer_Segment'] == 'Champions'][\n",
    "    ['CustomerID', 'Country', 'Monetary', 'Frequency', 'CLV', 'AvgOrderValue']\n",
    "].sort_values('CLV', ascending=False)\n",
    "\n",
    "at_risk_high_value = rfm_churn[\n",
    "    (rfm_churn['Customer_Segment'].isin(['At Risk', 'Cannot Lose Them'])) &\n",
    "    (rfm_churn['CLV'] > rfm_churn['CLV'].median())\n",
    "][['CustomerID', 'Customer_Segment', 'Country', 'Monetary', 'CLV', 'Churn_Probability']\n",
    " ].sort_values('CLV', ascending=False)\n",
    "\n",
    "champions_list.to_csv('output/powerbi_champions_customers.csv', index=False)\n",
    "at_risk_high_value.to_csv('output/powerbi_at_risk_high_value.csv', index=False)\n",
    "\n",
    "# Create Power BI data dictionary\n",
    "data_dictionary = \"\"\"\n",
    "# Power BI Data Dictionary - Customer Segmentation Analysis\n",
    "\n",
    "## powerbi_customer_analysis.csv (Main Dataset)\n",
    "- CustomerID: Unique customer identifier\n",
    "- Country: Customer country\n",
    "- Customer_Segment: RFM-based segment (Champions, At Risk, etc.)\n",
    "- ML_Cluster: Machine learning cluster assignment (0-4)\n",
    "- Recency: Days since last purchase\n",
    "- Frequency: Total number of orders\n",
    "- Monetary: Total customer revenue\n",
    "- RFM_Value: Combined RFM score (3-15)\n",
    "- AvgOrderValue: Average order amount\n",
    "- UniqueProducts: Number of different products purchased\n",
    "- CLV: Customer Lifetime Value prediction\n",
    "- Churn_Probability: ML-predicted churn probability (0-1)\n",
    "- Churn_Risk_Level: Low/Medium/High risk categories\n",
    "- RFM_Category: Low/Medium/High/Premium value tiers\n",
    "- CLV_Category: CLV quartile groupings\n",
    "- Recency_Category: Active/Recent/Dormant/Lost status\n",
    "\n",
    "## powerbi_segment_kpis.csv (KPI Dashboard)\n",
    "- Customer_Segment: Segment name\n",
    "- Customer_Count: Number of customers in segment\n",
    "- Total_Revenue: Segment revenue contribution\n",
    "- Avg_Revenue_Per_Customer: Average customer value\n",
    "- Customer_Percentage: % of total customer base\n",
    "- Revenue_Percentage: % of total revenue\n",
    "- CLV_Percentage: % of total predicted CLV\n",
    "- Avg_Churn_Risk: Average churn probability in segment\n",
    "\n",
    "## powerbi_monthly_cohorts.csv (Time Analysis)\n",
    "- CustomerID: Customer identifier\n",
    "- YearMonth: Transaction period (YYYY-MM format)\n",
    "- Monthly_Revenue: Customer revenue in that month\n",
    "- Monthly_Orders: Number of orders in month\n",
    "- Customer_Segment: Customer's segment classification\n",
    "- CLV_Category: Customer's CLV tier\n",
    "\n",
    "## powerbi_country_analysis.csv (Geographic Analysis)\n",
    "- Country: Country name\n",
    "- Total_Customers: Number of customers\n",
    "- Total_Revenue: Country revenue contribution\n",
    "- Total_CLV: Predicted CLV for country\n",
    "- Avg_Churn_Risk: Average churn risk in country\n",
    "- Avg_RFM_Score: Average RFM performance\n",
    "\"\"\"\n",
    "\n",
    "with open('output/powerbi_data_dictionary.txt', 'w') as f:\n",
    "    f.write(data_dictionary)\n",
    "\n",
    "print(\"\\nAll Power BI datasets exported successfully:\")\n",
    "print(\"- powerbi_customer_analysis.csv (4,146 customers)\")\n",
    "print(\"- powerbi_segment_kpis.csv (8 segments)\")\n",
    "print(\"- powerbi_monthly_cohorts.csv (monthly analysis)\")\n",
    "print(\"- powerbi_country_analysis.csv (geographic analysis)\")\n",
    "print(\"- powerbi_champions_customers.csv (top customers)\")\n",
    "print(\"- powerbi_at_risk_high_value.csv (retention focus)\")\n",
    "print(\"- powerbi_data_dictionary.txt\")\n",
    "print(\"\\nReady for Power BI dashboard creation!\")\n",
    "\n",
    "# Display key insights for dashboard design\n",
    "print(f\"\\nKey Insights for Dashboard:\")\n",
    "print(f\"• Champions segment: {segment_kpis[segment_kpis['Customer_Segment']=='Champions']['Revenue_Percentage'].iloc[0]}% of revenue\")\n",
    "print(f\"• At-risk revenue: ${rfm_churn[rfm_churn['Churn_Risk_Level']=='High']['Monetary'].sum():,.0f}\")\n",
    "print(f\"• Average CLV: ${rfm_churn['CLV'].mean():,.0f}\")\n",
    "print(f\"• Customers needing attention: {len(at_risk_high_value)} high-value at-risk customers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e718a41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
